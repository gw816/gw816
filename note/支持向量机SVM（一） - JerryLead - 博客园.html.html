<html>
<head>
  <title>支持向量机SVM（一） - JerryLead - 博客园.html</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="Evernote Windows/306387 (zh-CN, DDL); Windows/10.0.0 (Win64);"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="1101"/>
<h1>支持向量机SVM（一） - JerryLead - 博客园.html</h1>

<div>
<span><div><h5>【转载请注明出处】<a href="http://www.cnblogs.com/jerrylead">http://www.cnblogs.com/jerrylead</a></h5><h5>1 简介</h5><div style="margin-top: 1em; margin-bottom: 1em;">支持向量机基本上是最好的有监督学习算法了。最开始接触SVM是去年暑假的时候，老师要求交《统计学习理论》的报告，那时去网上下了一份入门教程，里面讲的很通俗，当时只是大致了解了一些相关概念。这次斯坦福提供的学习材料，让我重新学习了一些SVM知识。我看很多正统的讲法都是从VC 维理论和结构风险最小原理出发，然后引出SVM什么的，还有些资料上来就讲分类超平面什么的。这份材料从前几节讲的logistic回归出发，引出了SVM，既揭示了模型间的联系，也让人觉得过渡更自然。</div><h5>2 重新审视logistic回归</h5><div style="margin-top: 1em; margin-bottom: 1em;">Logistic回归目的是从特征学习出一个0/1分类模型，而这个模型是将特性的线性组合作为自变量，由于自变量的取值范围是负无穷到正无穷。因此，使用logistic函数（或称作sigmoid函数）将自变量映射到(0,1)上，映射后的值被认为是属于y=1的概率。</div><div style="margin-top: 1em; margin-bottom: 1em;">形式化表示就是</div><div style="margin-top: 1em; margin-bottom: 1em;">假设函数</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131373510.png"><img alt="clip_image001" border="0" src="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131375670.png" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image001" width="235"></img></a></div><div style="margin-top: 1em; margin-bottom: 1em;">其中x是n维特征向量，函数g就是logistic函数。</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113137969.png"><img alt="clip_image002" border="0" src="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131373129.png" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image002" width="124"></img></a>的图像是</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131375604.png"><img alt="clip_image003" border="0" src="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131388079.png" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image003" width="332"></img></a></div><div style="margin-top: 1em; margin-bottom: 1em;">可以看到，将无穷映射到了(0,1)。</div><div style="margin-top: 1em; margin-bottom: 1em;">而假设函数就是特征属于y=1的概率。</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131385015.png"><img alt="clip_image004" border="0" src="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131381950.png" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image004" width="245"></img></a></div><div style="margin-top: 1em; margin-bottom: 1em;">当我们要判别一个新来的特征属于哪个类时，只需求<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131389409.png"><img alt="clip_image006" border="0" src="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131393279.png" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image006" width="33"></img></a>，若大于0.5就是y=1的类，反之属于y=0类。</div><div style="margin-top: 1em; margin-bottom: 1em;">再审视一下<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131392374.png"><img alt="clip_image006[1]" border="0" src="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131408197.png" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image006[1]" width="33"></img></a>，发现<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131403704.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image.png" type="image/png" data-filename="Image.png" alt="clip_image006[2]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image006[2]" width="33"/></a>只和<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131416669.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [1].png" type="image/png" data-filename="Image.png" alt="clip_image008" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image008" width="23"/></a>有关，<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131416047.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [2].png" type="image/png" data-filename="Image.png" alt="clip_image008[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image008[1]" width="23"/></a>&gt;0，那么<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113142997.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [3].png" type="image/png" data-filename="Image.png" alt="clip_image010" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image010" width="70"/></a>，g(z)只不过是用来映射，真实的类别决定权还在<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131425948.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [4].png" type="image/png" data-filename="Image.png" alt="clip_image008[2]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image008[2]" width="23"/></a>。还有当<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113143898.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [5].png" type="image/png" data-filename="Image.png" alt="clip_image012" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image012" width="51"/></a>时，<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131433340.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [6].png" type="image/png" data-filename="Image.png" alt="clip_image006[3]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image006[3]" width="33"/></a>=1，反之<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131442402.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [7].png" type="image/png" data-filename="Image.png" alt="clip_image006[4]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image006[4]" width="33"/></a>=0。如果我们只从<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131456240.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [8].png" type="image/png" data-filename="Image.png" alt="clip_image008[3]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image008[3]" width="23"/></a>出发，希望模型达到的目标无非就是让训练数据中y=1的特征<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131458715.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [9].png" type="image/png" data-filename="Image.png" alt="clip_image012[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image012[1]" width="51"/></a>，而是y=0的特征<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131455617.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [10].png" type="image/png" data-filename="Image.png" alt="clip_image014" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image014" width="51"/></a>。Logistic回归就是要学习得到<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131464679.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [11].png" type="image/png" data-filename="Image.png" alt="clip_image016" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image016" width="8"/></a>，使得正例的特征远大于0，负例的特征远小于0，强调在全部训练实例上达到这个目标。</div><div style="margin-top: 1em; margin-bottom: 1em;">图形化表示如下：</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131479073.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [12].png" type="image/png" data-filename="Image.png" alt="clip_image017" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image017" width="362"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">中间那条线是<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131479879.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [13].png" type="image/png" data-filename="Image.png" alt="clip_image019" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image019" width="49"/></a>，logistic回顾强调所有点尽可能地远离中间那条线。学习出的结果也就中间那条线。考虑上面3个点A、B和C。从图中我们可以确定A是×类别的，然而C我们是不太确定的，B还算能够确定。这样我们可以得出结论，我们更应该关心靠近中间分割线的点，让他们尽可能地远离中间线，而不是在所有点上达到最优。因为那样的话，要使得一部分点靠近中间线来换取另外一部分点更加远离中间线。我想这就是支持向量机的思路和logistic回归的不同点，一个考虑局部（不关心已经确定远离的点），一个考虑全局（已经远离的点可能通过调整中间线使其能够更加远离）。这是我的个人直观理解。</div><h5>3 形式化表示</h5><div style="margin-top: 1em; margin-bottom: 1em;">我们这次使用的结果标签是y=-1,y=1，替换在logistic回归中使用的y=0和y=1。同时将<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131482006.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [14].png" type="image/png" data-filename="Image.png" alt="clip_image016[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image016[1]" width="8"/></a>替换成w和b。以前的<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131483368.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [15].png" type="image/png" data-filename="Image.png" alt="clip_image021" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image021" width="218"/></a>，其中认为<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131482256.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [16].png" type="image/png" data-filename="Image.png" alt="clip_image023" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image023" width="39"/></a>。现在我们替换<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113149794.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [17].png" type="image/png" data-filename="Image.png" alt="clip_image025" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image025" width="14"/></a>为b，后面替换<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131492157.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [18].png" type="image/png" data-filename="Image.png" alt="clip_image027" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image027" width="145"/></a>为<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131503760.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [19].png" type="image/png" data-filename="Image.png" alt="clip_image029" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image029" width="155"/></a>（即<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113150662.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [20].png" type="image/png" data-filename="Image.png" alt="clip_image031" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image031" width="26"/></a>）。这样，我们让<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131511152.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [21].png" type="image/png" data-filename="Image.png" alt="clip_image033" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image033" width="92"/></a>，进一步<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131513628.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [22].png" type="image/png" data-filename="Image.png" alt="clip_image035" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image035" width="186"/></a>。也就是说除了y由y=0变为y=-1，只是标记不同外，与logistic回归的形式化表示没区别。再明确下假设函数</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131518055.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [23].png" type="image/png" data-filename="Image.png" alt="clip_image037" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image037" width="136"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">上一节提到过我们只需考虑<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131526593.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [24].png" type="image/png" data-filename="Image.png" alt="clip_image008[4]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image008[4]" width="23"/></a>的正负问题，而不用关心g(z)，因此我们这里将g(z)做一个简化，将其简单映射到y=-1和y=1上。映射关系如下：</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131529908.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [25].png" type="image/png" data-filename="Image.png" alt="clip_image039" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image039" width="131"/></a></div><h5>4 函数间隔（functional margin）和几何间隔（geometric margin）</h5><div style="margin-top: 1em; margin-bottom: 1em;">给定一个训练样本<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131525971.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [26].png" type="image/png" data-filename="Image.png" alt="clip_image041" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image041" width="60"/></a>，x是特征，y是结果标签。i表示第i个样本。我们定义函数间隔如下：</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131534858.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [27].png" type="image/png" data-filename="Image.png" alt="clip_image043" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image043" width="135"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">可想而知，当<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131539808.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [28].png" type="image/png" data-filename="Image.png" alt="clip_image045" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image045" width="47"/></a>时，在我们的g(z)定义中，<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131545249.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [29].png" type="image/png" data-filename="Image.png" alt="clip_image047" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image047" width="90"/></a>，<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113155200.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [30].png" type="image/png" data-filename="Image.png" alt="clip_image049" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image049" width="20"/></a>的值实际上就是<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131552675.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [31].png" type="image/png" data-filename="Image.png" alt="clip_image051" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image051" width="73"/></a>。反之亦然。为了使函数间隔最大（更大的信心确定该例是正例还是反例），当<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131559577.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [32].png" type="image/png" data-filename="Image.png" alt="clip_image045[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image045[1]" width="47"/></a>时，<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131564528.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [33].png" type="image/png" data-filename="Image.png" alt="clip_image053" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image053" width="64"/></a>应该是个大正数，反之是个大负数。因此函数间隔代表了我们认为特征是正例还是反例的确信度。</div><div style="margin-top: 1em; margin-bottom: 1em;">继续考虑w和b，如果同时加大w和b，比如在<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131568639.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [34].png" type="image/png" data-filename="Image.png" alt="clip_image055" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image055" width="75"/></a>前面乘个系数比如2，那么所有点的函数间隔都会增大二倍，这个对求解问题来说不应该有影响，因为我们要求解的是<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131569478.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [35].png" type="image/png" data-filename="Image.png" alt="clip_image057" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image057" width="77"/></a>，同时扩大w和b对结果是无影响的。这样，我们为了限制w和b，可能需要加入归一化条件，毕竟求解的目标是确定唯一一个w和b，而不是多组线性相关的向量。这个归一化一会再考虑。</div><div style="margin-top: 1em; margin-bottom: 1em;">刚刚我们定义的函数间隔是针对某一个样本的，现在我们定义全局样本上的函数间隔</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131573905.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [36].png" type="image/png" data-filename="Image.png" alt="clip_image058" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image058" width="129"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">说白了就是在训练样本上分类正例和负例确信度最小那个函数间隔。</div><div style="margin-top: 1em; margin-bottom: 1em;">接下来定义几何间隔，先看图</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131571364.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [37].png" type="image/png" data-filename="Image.png" alt="clip_image059" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image059" width="362"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">假设我们有了B点所在的<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113158426.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [38].png" type="image/png" data-filename="Image.png" alt="clip_image057[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image057[1]" width="77"/></a>分割面。任何其他一点，比如A到该面的距离以<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131584820.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [39].png" type="image/png" data-filename="Image.png" alt="clip_image061" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image061" width="21"/></a>表示，假设B就是A在分割面上的投影。我们知道向量BA的方向是<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131593359.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [40].png" type="image/png" data-filename="Image.png" alt="clip_image063" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image063" width="11"/></a>（分割面的梯度），单位向量是<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131593608.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [41].png" type="image/png" data-filename="Image.png" alt="clip_image065" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image065" width="21"/></a>。A点是<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132006050.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [42].png" type="image/png" data-filename="Image.png" alt="clip_image041[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image041[1]" width="60"/></a>，所以B点是x=<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132002114.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [43].png" type="image/png" data-filename="Image.png" alt="clip_image067" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image067" width="82"/></a>（利用初中的几何知识），带入<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132002637.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [44].png" type="image/png" data-filename="Image.png" alt="clip_image057[2]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image057[2]" width="77"/></a>得，</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132011524.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [45].png" type="image/png" data-filename="Image.png" alt="clip_image069" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image069" width="170"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">进一步得到</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132017588.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [46].png" type="image/png" data-filename="Image.png" alt="clip_image070" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image070" width="345"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132018394.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [47].png" type="image/png" data-filename="Image.png" alt="clip_image061[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image061[1]" width="21"/></a>实际上就是点到平面距离。</div><div style="margin-top: 1em; margin-bottom: 1em;">再换种更加优雅的写法：</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113202836.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [48].png" type="image/png" data-filename="Image.png" alt="clip_image071" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image071" width="293"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">当<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132024914.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [49].png" type="image/png" data-filename="Image.png" alt="clip_image073" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image073" width="55"/></a>时，不就是函数间隔吗？是的，前面提到的函数间隔归一化结果就是几何间隔。他们为什么会一样呢？因为函数间隔是我们定义的，在定义的时候就有几何间隔的色彩。同样，同时扩大w和b，w扩大几倍，<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132037880.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [50].png" type="image/png" data-filename="Image.png" alt="clip_image075" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image075" width="29"/></a>就扩大几倍，结果无影响。同样定义全局的几何间隔<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132042274.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [51].png" type="image/png" data-filename="Image.png" alt="clip_image076" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image076" width="141"/></a></div><h5>5 最优间隔分类器（optimal margin classifier）</h5><div style="margin-top: 1em; margin-bottom: 1em;">回想前面我们提到我们的目标是寻找一个超平面，使得离超平面比较近的点能有更大的间距。也就是我们不考虑所有的点都必须远离超平面，我们关心求得的超平面能够让所有点中离它最近的点具有最大间距。形象的说，我们将上面的图看作是一张纸，我们要找一条折线，按照这条折线折叠后，离折线最近的点的间距比其他折线都要大。形式化表示为：</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132042241.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [52].png" type="image/png" data-filename="Image.png" alt="clip_image077" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image077" width="368"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">这里用<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132053047.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [53].png" type="image/png" data-filename="Image.png" alt="clip_image075[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image075[1]" width="29"/></a>=1规约w，使得<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132059634.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [54].png" type="image/png" data-filename="Image.png" alt="clip_image079" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image079" width="51"/></a>是几何间隔。</div><div style="margin-top: 1em; margin-bottom: 1em;">到此，我们已经将模型定义出来了。如果求得了w和b，那么来一个特征x，我们就能够分类了，称为最优间隔分类器。接下的问题就是如何求解w和b的问题了。</div><div style="margin-top: 1em; margin-bottom: 1em;">由于<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132067059.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [55].png" type="image/png" data-filename="Image.png" alt="clip_image081" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image081" width="55"/></a>不是凸函数，我们想先处理转化一下，考虑几何间隔和函数间隔的关系，<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/2011031311320658.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [56].png" type="image/png" data-filename="Image.png" alt="clip_image083" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image083" width="47"/></a>，我们改写一下上面的式子：</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132079992.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [57].png" type="image/png" data-filename="Image.png" alt="clip_image084" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image084" width="353"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">这时候其实我们求的最大值仍然是几何间隔，只不过此时的w不受<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113207482.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [58].png" type="image/png" data-filename="Image.png" alt="clip_image081[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image081[1]" width="55"/></a>的约束了。然而这个时候目标函数仍然不是凸函数，没法直接代入优化软件里计算。我们还要改写。前面说到同时扩大w和b对结果没有影响，但我们最后要求的仍然是w和b的确定值，不是他们的一组倍数值，因此，我们需要对<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132088257.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [59].png" type="image/png" data-filename="Image.png" alt="clip_image086" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image086" width="8"/></a>做一些限制，以保证我们解是唯一的。这里为了简便我们取<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132099270.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [60].png" type="image/png" data-filename="Image.png" alt="clip_image088" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image088" width="34"/></a>。这样的意义是将全局的函数间隔定义为1，也即是将离超平面最近的点的距离定义为<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132093108.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [61].png" type="image/png" data-filename="Image.png" alt="clip_image090" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image090" width="21"/></a>。由于求<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/20110313113210534.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [62].png" type="image/png" data-filename="Image.png" alt="clip_image090[1]" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image090[1]" width="21"/></a>的最大值相当于求<a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132107120.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [63].png" type="image/png" data-filename="Image.png" alt="clip_image092" border="0" style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image092" width="43"/></a>的最小值，因此改写后结果为：</div><div style="margin-top: 1em; margin-bottom: 1em;"><a href="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131132112071.png"><img src="支持向量机SVM（一） - JerryLead - 博客园.html_files/Image [64].png" type="image/png" data-filename="Image.png" alt="clip_image093" border="0" style="background-image: none; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image093" width="358"/></a></div><div style="margin-top: 1em; margin-bottom: 1em;">这下好了，只有线性约束了，而且是个典型的二次规划问题（目标函数是自变量的二次函数）。代入优化软件可解。</div><div style="margin-top: 1em; margin-bottom: 1em;">到这里发现，这个讲义虽然没有像其他讲义一样先画好图，画好分类超平面，在图上标示出间隔那么直观，但每一步推导有理有据，依靠思路的流畅性来推导出目标函数和约束。</div><div style="margin-top: 1em; margin-bottom: 1em;">接下来介绍的是手工求解的方法了，一种更优的求解方法。</div></div></span>
</div></body></html> 